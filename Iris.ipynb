{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNH8YYlt2NXeUyEHtQk5kKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryabhatt-O/ML-Feat-Computational-Geometry/blob/main/Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGQKG3gO3CVa"
      },
      "source": [
        "# **PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNepxIczAXWa"
      },
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "# pca = PCA(n_components=2)\n",
        "# X_r_2d = pca.fit(X).transform(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plt.figure()\n",
        "# colors = ['navy', 'turquoise', 'darkorange']\n",
        "# lw = 2\n",
        "\n",
        "# for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
        "#     plt.scatter(X_r_2d[y == i, 0], X_r_2d[y == i, 1], color=color, alpha=.8, lw=lw,\n",
        "#                 label=target_name)\n",
        "# plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
        "# plt.title('PCA of IRIS dataset')\n",
        "\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "6MoucVRpxHxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "tsne = TSNE(n_components=2, init='random', random_state=0)\n",
        "X_r_2d = tsne.fit_transform(X)"
      ],
      "metadata": {
        "id": "KkzXvZTXXuiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_r_2d)"
      ],
      "metadata": {
        "id": "JPQbMvX5YEZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9rIauSp3Lv_"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShLiXW7lRFj3"
      },
      "source": [
        "import numpy as np\n",
        "for i,j in enumerate(X):\n",
        "  print(\"point\",[i],\"-->\",X[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "for i,j in enumerate(X_r_2d):\n",
        "  print(\"point\",[i],\"-->\",X_r_2d[i])"
      ],
      "metadata": {
        "id": "buwtk7juPQxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New Algo**"
      ],
      "metadata": {
        "id": "igDXqgqg34CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_r_2d_uniq = np.unique(X_r_2d,axis = 0) \n",
        "len(X_r_2d_uniq)  "
      ],
      "metadata": {
        "id": "TO_wgpNI33gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the first point P1  randomly from the X_r_2d points.\n",
        "P1 = X_r_2d_uniq[0]\n",
        "#Find distance of the chosen point  to each of the remaining N-1 points\n",
        "from scipy.spatial import distance\n",
        "distances = distance.cdist([P1], X_r_2d_uniq[1:])\n",
        "# Choose the point P2 which is the farthest from the remaining N-1 points.\n",
        "# P2 = X_r_2d_uniq[1:][np.argmax(distances)]\n",
        "P2 = X_r_2d_uniq[np.argmax(distances)]\n",
        "centroid = [P1,P2]\n",
        "# # n = [len(X_r_2d)*0.10-len(c)]\n",
        "X_r_2d_remaining = []\n"
      ],
      "metadata": {
        "id": "ET5jMG9__AxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_percent  = int(input(\"enter the %: \"))\n",
        "num = (my_percent/100 * len(X_r_2d))\n",
        "for i in range(int(num-(len(centroid)))):\n",
        "  # map = len(centroid)\n",
        "  X_r_2d_remaining = np.delete(X_r_2d_uniq, np.where(X_r_2d_uniq == centroid[i]), axis=0)\n",
        "  distances = distance.cdist(X_r_2d_remaining,centroid)\n",
        "  min_in_row = np.min(distances, axis = 1)\n",
        "  centroid.append(X_r_2d_remaining[min_in_row.argmax()])\n",
        "        \n",
        "\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "c0lc6p1O_D4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(centroid)"
      ],
      "metadata": {
        "id": "4HEr5xCN_QY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6aCpNGL3SCD"
      },
      "source": [
        "# **10% of Total used as Centroid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN5CCTKZSfWM"
      },
      "source": [
        "# import numpy as np\n",
        "# centroid = X_r_2d[np.random.randint(X_r_2d.shape[0], size=15), :]\n",
        "# print(centroid)\n",
        "\n",
        "# if len(np.unique(centroid, axis=0)) == len(centroid) :\n",
        "#   print(\"GO AHEAD\")\n",
        "# else:\n",
        "#   print(\"RE-SHUFFLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10% selection from Kmeans++**"
      ],
      "metadata": {
        "id": "HPCqQRV8gnjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn import datasets\n",
        "# from sklearn.cluster import KMeans\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.patches as mpatches\n",
        "# import sklearn.metrics as sm\n",
        "# %matplotlib inline\n",
        "\n",
        "# # -----------------------------------------------------\n",
        "\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "# print(iris.data)\n",
        "\n",
        "# # -----------------------------------\n",
        "# x = pd.DataFrame(iris.data, columns=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width'])\n",
        "# y = pd.DataFrame(iris.target, columns=['Target'])\n",
        "\n",
        "# # -------------------------------\n",
        "# iris_k_mean_model = KMeans(n_clusters=3)\n",
        "# iris_k_mean_model.fit(x)\n",
        "\n",
        "# # ------------------------\n",
        "\n",
        "# {i: np.where(iris_k_mean_model.labels_ == i)[0] for i in range(iris_k_mean_model.n_clusters)}\n",
        "\n",
        "# # --------------------------------------------------------------------------------------------------\n",
        "\n",
        "# from collections import Counter, defaultdict\n",
        "# print(Counter(iris_k_mean_model.labels_))\n",
        "# # -------------------------------------------------\n",
        "\n",
        "# x_np = x.to_numpy()\n",
        "\n",
        "# # ----------------------------------\n",
        "# cluster_info = {i: x[np.where(iris_k_mean_model.labels_ == i)] for i in range(iris_k_mean_model.n_clusters)}\n",
        "# cluster_info\n",
        "# # -----------------------------------\n",
        "\n",
        "# cluster_info_10_random = {i: cluster_info[i][np.random.choice(cluster_info[i].shape[0], 10, replace=False)] for i in range(iris_k_mean_model.n_clusters)}\n",
        "\n",
        "# # ----------------------------------\n",
        "\n",
        "# centroid_nd = np.concatenate(list(cluster_info_10_random.values()))\n",
        "# len(centroid_nd)"
      ],
      "metadata": {
        "id": "u5tOoE_Aglaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pca = PCA(n_components=2)\n",
        "# centroid = pca.fit(centroid_nd).transform(centroid_nd)"
      ],
      "metadata": {
        "id": "RXghmP_tifvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# centroid"
      ],
      "metadata": {
        "id": "U2f1QlfRk8XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV6lQ7H5hxj3"
      },
      "source": [
        "### **These are the numbers of Original X_r_2d from which Centriods are taken**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HosP659gWRm"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import spatial\n",
        "\n",
        "def find_nearest(big_array,small_array,tolerance):\n",
        "    tree_big=spatial.cKDTree(big_array)\n",
        "    tree_small=spatial.cKDTree(small_array)\n",
        "    return tree_small.query_ball_tree(tree_big,r=tolerance)\n",
        "\n",
        "higher_dim_index = []\n",
        "higher_dim_index = find_nearest(X_r_2d,centroid,0)\n",
        "print(higher_dim_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rest_data = np.delete(X_r_2d, higher_dim_index, axis=0)"
      ],
      "metadata": {
        "id": "QSxHloDamdtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlRAlrCC3aJH"
      },
      "source": [
        "# **Rest Test Data**(Which are different from centroid points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkzdVfBwVHPj"
      },
      "source": [
        "# rest_data = X_r_2d[np.random.choice(X_r_2d.shape[0], 150, replace=False), :]\n",
        "# print(rest_data)\n",
        "# rest_data = pca.fit(rest_data_nd).transform(rest_data_nd)\n",
        "\n",
        "\n",
        "# if len(np.unique(rest_data, axis=0)) == 135:\n",
        "#   print(\"GO AHEAD\")\n",
        "# else:\n",
        "#   print(\"RE-SHUFFLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUBZiDW05tB0"
      },
      "source": [
        "# **Centroid points are given to create Voronoi upon which Rest Test_data is distributed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkFfD7GSKGRF"
      },
      "source": [
        "from random import *\n",
        "import heapq\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# For checking from voronoi\n",
        "\n",
        "from random import *\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
        "import numpy as np\n",
        "vor = Voronoi(centroid,qhull_options='Qbb Qc Qx')\n",
        "voronoi_plot_2d(vor,show_vertices = True)\n",
        "\n",
        "#for plotting my friends location \n",
        "x, y = rest_data.T\n",
        "plt.plot(x,y, 'ko')\n",
        "\n",
        "for region in vor.regions:\n",
        "    if not -1 in region:\n",
        "        polygon = [vor.vertices[i] for i in region]\n",
        "        plt.fill(*zip(*polygon))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm-bcTDA6FPk"
      },
      "source": [
        "# **Numbering Voronoi Cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0JQ6Xwh0Voh"
      },
      "source": [
        "\n",
        "for i,a in enumerate(centroid):\n",
        "   print(\"Centriod index ---> \",a,\"corresponding vor_cell -->\",vor.point_region[i])\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6_JQU_i0csO"
      },
      "source": [
        "from scipy.spatial import cKDTree\n",
        "voronoi_kdtree = cKDTree(centroid)\n",
        "test_point_dist, test_point_regions = voronoi_kdtree.query(rest_data)\n",
        "l= test_point_regions\n",
        "m = test_point_dist\n",
        "print(l)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9MID8zed5Cn"
      },
      "source": [
        "# **{Vor_CELL number : index of points inside that region referred to rest_points}**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Muw_yORdrSX"
      },
      "source": [
        "from collections import defaultdict\n",
        "cell_wise_point = []\n",
        "def list_duplicates(l):\n",
        "    tally = defaultdict(list)\n",
        "    for i,item in enumerate(l):\n",
        "        tally[item].append(i)\n",
        "    return ((key,locs) for key,locs in tally.items() \n",
        "                            if len(locs)>1)\n",
        "\n",
        "for dup in sorted(list_duplicates(l)):\n",
        "    # print(dup)\n",
        "    cell_wise_point.append(dup)\n",
        "\n",
        "c_w_cord = dict(cell_wise_point)\n",
        "print(c_w_cord)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMcQu6ElfqWn"
      },
      "source": [
        "vor_reg = []\n",
        "vor_inside_points = []\n",
        "for key in c_w_cord.keys():\n",
        "    for i in c_w_cord.get(key):\n",
        "        print('cell',key,'-->','co-ordinates',rest_data[i])\n",
        "        vor_reg.append(key)\n",
        "        vor_inside_points.append(rest_data[i])\n",
        "\n",
        "\n",
        "print(vor_reg,vor_inside_points)\n",
        "\n",
        "type(vor_inside_points)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azuFJCQSgLhn"
      },
      "source": [
        "# **{Vor_CELL number : Co-Ordinates of points inside that region}**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28m09C56gCRD"
      },
      "source": [
        "vor_inside_point_coOrdinates = {}\n",
        "i = iter(vor_reg)\n",
        "j = iter(vor_inside_points)\n",
        "k = list(zip(i, j))\n",
        "for (x,y) in k:\n",
        "    if x in vor_inside_point_coOrdinates:\n",
        "        vor_inside_point_coOrdinates[x] = vor_inside_point_coOrdinates[x] , y # whatever function needs to be to combine them\n",
        "    else:\n",
        "        vor_inside_point_coOrdinates[x] = y\n",
        "\n",
        "vor_inside_point_coOrdinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMRah8BCgZf1"
      },
      "source": [
        "# **{Vor_CELL number : sum of Co-Ordinates of points regionwise}**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2fMewvCgPGv"
      },
      "source": [
        "vor_inside_point_sum = {}\n",
        "i = iter(vor_reg)\n",
        "j = iter(vor_inside_points)\n",
        "k = list(zip(i, j))\n",
        "for (x,y) in k:\n",
        "    if x in vor_inside_point_sum:\n",
        "        vor_inside_point_sum[x] = vor_inside_point_sum[x] + y # whatever function needs to be to combine them\n",
        "    else:\n",
        "        vor_inside_point_sum[x] = y\n",
        "\n",
        "vor_inside_point_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhVS5CsPgshl"
      },
      "source": [
        "# **{Vor_CELL number : Total No of points  of point regionWise}**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phwYjH5KgbwE"
      },
      "source": [
        "unique, counts = np.unique(l, return_counts=True)\n",
        "vor_inside_point_count = dict(zip(unique, counts))\n",
        "print(vor_inside_point_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTQQzQPBg8Qx"
      },
      "source": [
        "# **Pseudo-Centroid**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvPqG83giL_C"
      },
      "source": [
        "{k: vor_inside_point_sum[k]/vor_inside_point_count[k] for k in vor_inside_point_sum.keys() & vor_inside_point_count}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyQ1vdQ8gvLf"
      },
      "source": [
        "Pseudo_centroid = []\n",
        "Pseudo_centroid_dict = {k: vor_inside_point_sum[k]/vor_inside_point_count[k] for k in vor_inside_point_sum.keys() & vor_inside_point_count}\n",
        "Pseudo_centroid = Pseudo_centroid_dict.values()\n",
        "Pseudo_centroid_list = list(Pseudo_centroid) \n",
        "\n",
        "Pseudo_centroid_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge82l3ntDTAI"
      },
      "source": [
        "### ***CosineWay***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjJ3ItUchYsx"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "distance_matrix= cosine_similarity(Pseudo_centroid_list,Pseudo_centroid_list)\n",
        "print(distance_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo_0v1XpnwMz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEEzXkAoocgK"
      },
      "source": [
        "# **DATAFRAME of CosineMatrix of Pseudo-Centroids**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4W5i03UnYJ1"
      },
      "source": [
        "import pandas as pd\n",
        "data_frame = pd.DataFrame(distance_matrix)\n",
        "\n",
        "print(data_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur0cEycXpSTk"
      },
      "source": [
        "data_frame[\"SUM of roWs\"] = data_frame.sum(axis=1)\n",
        "\n",
        "print(data_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfT9Fx38p1YT"
      },
      "source": [
        "# **TOP 3 Pseudo-Centroid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3BWbDrNphR-"
      },
      "source": [
        "k_vector = data_frame.nsmallest(3, 'SUM of roWs')\n",
        "k_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvk9wgIpkvZG"
      },
      "source": [
        "index = k_vector.index\n",
        "index.name = \"Index\"\n",
        "k_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOS3KCbo8fzw"
      },
      "source": [
        "### ***Eucledian_way***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7CVtK387svR"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "euclidean_Pseudo_matrix = distance.cdist(Pseudo_centroid_list,Pseudo_centroid_list, 'euclidean')\n",
        "euclidean_Pseudo_data_frame = pd.DataFrame(euclidean_Pseudo_matrix)\n",
        "\n",
        "print(euclidean_Pseudo_data_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o4eLAF-7tGQ"
      },
      "source": [
        "euclidean_Pseudo_data_frame[\"SUM of roWs\"] = euclidean_Pseudo_data_frame.sum(axis=1)\n",
        "\n",
        "print(euclidean_Pseudo_data_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8KC5gLh801_"
      },
      "source": [
        "eu_vector = euclidean_Pseudo_data_frame.nlargest(3, 'SUM of roWs')\n",
        "eu_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk9fhFfe9Baa"
      },
      "source": [
        "index = eu_vector.index\n",
        "index.name = \"Index\"\n",
        "eu_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_4gSWYn3Yhb"
      },
      "source": [
        "# **Translating to Higher-Dimension**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsWrpIFz7Kwm"
      },
      "source": [
        "### ***Step-1***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1EmHm4N0Fkp"
      },
      "source": [
        "final_pseudo_vectors = []\n",
        "list1 =  list((k_vector.index))\n",
        "for i in list1:\n",
        "  final_pseudo_vectors.append(Pseudo_centroid_list[i])\n",
        "\n",
        "\n",
        "final_pseudo_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQQfDFEb9kVq"
      },
      "source": [
        "final_pseudo_vectors_eu = []\n",
        "list1 =  list((eu_vector.index))\n",
        "for i in list1:\n",
        "  final_pseudo_vectors_eu.append(Pseudo_centroid_list[i])\n",
        "\n",
        "\n",
        "final_pseudo_vectors_eu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd2Sws247P_j"
      },
      "source": [
        "### ***Step-2***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Q0TFn9jzRm"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "pseudo_to_original_centroid_mapping = distance.cdist(final_pseudo_vectors, centroid, 'euclidean')\n",
        "pseudo_to_original_centroid_mapping_data_frame = pd.DataFrame(pseudo_to_original_centroid_mapping)\n",
        "\n",
        "print(pseudo_to_original_centroid_mapping_data_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg3hi1LK9-w6"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "pseudo_to_original_centroid_mapping_eu = distance.cdist(final_pseudo_vectors_eu, centroid, 'euclidean')\n",
        "pseudo_to_original_centroid_mapping_data_frame_eu = pd.DataFrame(pseudo_to_original_centroid_mapping_eu)\n",
        "\n",
        "print(pseudo_to_original_centroid_mapping_data_frame_eu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JayM_pap7Tkk"
      },
      "source": [
        "### ***Step-3***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jFywwehjycO"
      },
      "source": [
        "mapping =  pseudo_to_original_centroid_mapping_data_frame.idxmin(axis=1)\n",
        "mapping_data_frame = pd.DataFrame(mapping)\n",
        "index = mapping_data_frame.index\n",
        "index.name = \"Pseudo-centroid\"\n",
        "mapping_data_frame.columns = ['Corresponding_original_Centroid']\n",
        "mapping_data_frame\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAL3MzPB-cX3"
      },
      "source": [
        "mapping_eu =  pseudo_to_original_centroid_mapping_data_frame_eu.idxmin(axis=1)\n",
        "mapping_data_frame_eu = pd.DataFrame(mapping_eu)\n",
        "index = mapping_data_frame_eu.index\n",
        "index.name = \"Pseudo-centroid\"\n",
        "mapping_data_frame_eu.columns = ['Corresponding_original_Centroid']\n",
        "mapping_data_frame_eu\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1jjx1hQ7Y6b"
      },
      "source": [
        "### ***Step-4***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HnoZr3qjHnT"
      },
      "source": [
        "final_centroid_vectors = []\n",
        "list2 =  list((mapping_data_frame.Corresponding_original_Centroid))\n",
        "for i in list2:\n",
        "  final_centroid_vectors.append(centroid[i])\n",
        "\n",
        "\n",
        "final_centroid_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1A5H7C9-zHq"
      },
      "source": [
        "final_centroid_vectors_eu = []\n",
        "list2_eu =  list((mapping_data_frame_eu.Corresponding_original_Centroid))\n",
        "for i in list2_eu:\n",
        "  final_centroid_vectors_eu.append(centroid[i])\n",
        "\n",
        "\n",
        "final_centroid_vectors_eu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELgxPoBn7dA3"
      },
      "source": [
        "### ***Step-5***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11PHD4WL5UDO"
      },
      "source": [
        "high_dim_centroid = []\n",
        "for i in list2:\n",
        "  high_dim_centroid.append(X[i])\n",
        "\n",
        "high_dim_centroid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7E5pvLE_HOK"
      },
      "source": [
        "high_dim_centroid_eu = []\n",
        "for i in list2_eu:\n",
        "  high_dim_centroid_eu.append(X[i])\n",
        "\n",
        "high_dim_centroid_eu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average of all points in two arrays indexwise\n",
        "def average_of_two_arrays(array1,array2):\n",
        "    for i in range(len(array1)):\n",
        "        array1[i] = (array1[i] + array2[i])/2\n",
        "    return array1\n",
        "    \n",
        "\n",
        "\n",
        "(average_of_two_arrays(high_dim_centroid,high_dim_centroid_eu))"
      ],
      "metadata": {
        "id": "TO7fIVLfld0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means Part**"
      ],
      "metadata": {
        "id": "Xfponlc2oMvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import sklearn.metrics as sm\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "pRw3LHMJoMCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "print(iris.data)"
      ],
      "metadata": {
        "id": "hvlwBTKboLP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "print(iris.data)"
      ],
      "metadata": {
        "id": "RDAw8XQIockE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris.target)"
      ],
      "metadata": {
        "id": "zRWNNms4oc-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.DataFrame(iris.data, columns=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width'])\n",
        "y = pd.DataFrame(iris.target, columns=['Target'])"
      ],
      "metadata": {
        "id": "1y3ybSIqodCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "-yBJv9eyYgcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,3))\n",
        "colors = np.array(['red', 'green', 'blue'])\n",
        "iris_targets_legend = np.array(iris.target_names)\n",
        "red_patch = mpatches.Patch(color='red', label='Setosa')\n",
        "green_patch = mpatches.Patch(color='green', label='Versicolor')\n",
        "blue_patch = mpatches.Patch(color='blue', label='Virginica')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(x['Sepal Length'], x['Sepal Width'], c=colors[y['Target']])\n",
        "plt.title('Sepal Length vs Sepal Width')\n",
        "plt.legend(handles=[red_patch, green_patch, blue_patch])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(x['Petal Length'], x['Petal Width'], c= colors[y['Target']])\n",
        "plt.title('Petal Length vs Petal Width')\n",
        "plt.legend(handles=[red_patch, green_patch, blue_patch])"
      ],
      "metadata": {
        "id": "jwYwdoA0mff3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "OYSFtGC_ZDZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_k_mean_model = KMeans(n_clusters=3)\n",
        "iris_k_mean_model.fit(x)"
      ],
      "metadata": {
        "id": "seCl9BDmodI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  high_dim_centroid_arr = np.asarray(high_dim_centroid, dtype=np.float32)\n",
        "high_dim_centroid_eu_arr = np.asarray(high_dim_centroid_eu, dtype=np.float32) \n",
        "type(high_dim_centroid_eu_arr)"
      ],
      "metadata": {
        "id": "KLYlVLHFqiKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Kmeans classifier\n",
        "iris_k_mean_model_vor =  KMeans(n_clusters=3,init = high_dim_centroid_eu_arr,n_init =1)\n",
        "iris_k_mean_model_vor.fit(X)"
      ],
      "metadata": {
        "id": "VAq1Xi3YodYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_k_mean_model_vor.labels_"
      ],
      "metadata": {
        "id": "34RcroNlodup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target"
      ],
      "metadata": {
        "id": "eE70LgUTG5Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sse = iris_k_mean_model_vor.inertia_ \n",
        "sse"
      ],
      "metadata": {
        "id": "DREjASpwod6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,3))\n",
        "\n",
        "colors = np.array(['red', 'green', 'blue'])\n",
        "\n",
        "predictedY = np.choose(iris_k_mean_model_vor.labels_, [2, 1, 0]).astype(np.int64)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(x['Petal Length'], x['Petal Width'], c=colors[y['Target']])\n",
        "plt.title('Before classification')\n",
        "plt.legend(handles=[red_patch, green_patch, blue_patch])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(x['Petal Length'], x['Petal Width'], c=colors[predictedY])\n",
        "plt.title(\"Model's classification\")\n",
        "plt.legend(handles=[red_patch, green_patch, blue_patch])"
      ],
      "metadata": {
        "id": "T-ibk95VFcb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "print(f'Silhouette Score(n=3): {silhouette_score(x,iris_k_mean_model_vor.labels_)}')"
      ],
      "metadata": {
        "id": "8TIrgWDVoeD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Compute the Davies-Bouldin score**.\n",
        "\n",
        "**The score is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances. Thus, clusters which are farther apart and less dispersed will result in a better score.**\n",
        "\n",
        "**The minimum score is zero, with lower values indicating better clustering.**"
      ],
      "metadata": {
        "id": "k0uatxCCPTAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import davies_bouldin_score\n",
        "print(davies_bouldin_score(x,predictedY))"
      ],
      "metadata": {
        "id": "SQflCOi8O_Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "metrics.calinski_harabasz_score(iris.data,iris_k_mean_model_vor.labels_)"
      ],
      "metadata": {
        "id": "67WkRw_LTAMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Patch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "\n",
        "colors = np.array(['red', 'green', 'blue'])\n",
        "\n",
        "predictedY = np.choose(iris_k_mean_model_vor.labels_, [2, 0, 1]).astype(np.int64)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(x['Petal Length'], x['Petal Width'], c=colors[y['Target']])\n",
        "plt.title('Before classification')\n",
        "plt.legend(handles=[red_patch, green_patch, blue_patch])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(x['Petal Length'], x['Petal Width'], c=colors[predictedY])\n",
        "plt.title(\"Model's classification\")\n",
        "plt.legend(handles=[red_patch, green_patch, blue_patch])"
      ],
      "metadata": {
        "id": "dE9n845tlHEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target"
      ],
      "metadata": {
        "id": "4isai4BXvemJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictedY"
      ],
      "metadata": {
        "id": "mLMJxrCtviqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VALIDATION**"
      ],
      "metadata": {
        "id": "D3NmTIS0afYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = train_data.target.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xvalid, ytrain, yvalid = train_test_split(X_r_2d, y.values, \n",
        "                                                  stratify=y, \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.1, shuffle=True)"
      ],
      "metadata": {
        "id": "mFmSxGRhwr4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
        "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
        "    :param actual: Array containing the actual target classes\n",
        "    :param predicted: Matrix with class predictions, one probability per class\n",
        "    \"\"\"\n",
        "    # Convert 'actual' to a binary array if it's not already:\n",
        "    if len(actual.shape) == 1:\n",
        "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "        for i, val in enumerate(actual):\n",
        "            actual2[i, val] = 1\n",
        "        actual = actual2\n",
        "\n",
        "    clip = np.clip(predicted, eps, 1 - eps)\n",
        "    rows = actual.shape[0]\n",
        "    vsota = np.sum(actual * np.log(clip))\n",
        "    return -1.0 / rows * vsota"
      ],
      "metadata": {
        "id": "vsj04FOsu6SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "DmimG2i-wDBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logLoss = multiclass_logloss(yvalid,predictedY)\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid,predictedY))"
      ],
      "metadata": {
        "id": "ZXx6RiAau5VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "print(classification_report(iris.target,predictedY))"
      ],
      "metadata": {
        "id": "kl_AQ7Ysae-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Accuracy**"
      ],
      "metadata": {
        "id": "lwv-pVjc8yE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(iris.target,predictedY))\n",
        "accuracy = accuracy_score(iris.target,predictedY)"
      ],
      "metadata": {
        "id": "8Whc945hoeHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# percent_list = []\n",
        "# sse_list = []\n",
        "# hello_check = []\n",
        "# accuracy_list =  []\n",
        "# logLoss_list = []\n",
        "percent_list.append(my_percent)\n",
        "sse_list.append(sse)\n",
        "accuracy_list.append(accuracy)\n",
        "logLoss_list.append(logLoss)\n",
        "# hello_check.extend((my_percent,sse,accuracy))"
      ],
      "metadata": {
        "id": "ZUUGAg3ZlA1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_count = dict(zip(percent_list,sse_list))\n",
        "freq_count"
      ],
      "metadata": {
        "id": "Q2heLZLzlHKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find = freq_count.items()\n",
        "from operator import itemgetter\n",
        "min_key, _ = min(freq_count.items(), key=itemgetter(1))\n",
        "(min_key, _)"
      ],
      "metadata": {
        "id": "jwQsSwVblHx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner  = dict(zip(percent_list,logLoss_list))\n",
        "tuner"
      ],
      "metadata": {
        "id": "Qdc4kkNplLqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwXyMxJU7Auy"
      },
      "source": [
        "# ***END***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(m)"
      ],
      "metadata": {
        "id": "9-kWQ1sXf4CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj0WcQGZ6L7d"
      },
      "source": [
        "# **This depicts Which voronoi cell contains how many test data points**\n",
        "\n",
        "{*Cell No* : **No of points assosiated in it**}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDzE3V9L0VyG"
      },
      "source": [
        "\n",
        "unique, counts = np.unique(l, return_counts=True)\n",
        "count = dict(zip(unique, counts))\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyzGgKXHfAjY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HnChvAxFtZ0"
      },
      "source": [
        "# **Region Vertices**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQavEzfRYF5i"
      },
      "source": [
        "for i in (range(len(centroid))):\n",
        "  print(\"points\",[i], \"=\", centroid[i])\n",
        "  print( 'and corresponding voronoi region','-->',[vor.point_region[i]],)\n",
        "  print(\"vertices for region for point\",i,\"=\", vor.regions[vor.point_region[i]])\n",
        "  print(\"coordinate of Voronoi vertices associated with point\", i,\":\")\n",
        "  print(vor.vertices[vor.regions[vor.point_region[i]]])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6N8zVL5IZw8"
      },
      "source": [
        "print(vor.point_region)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laE0ZAWQDSpX"
      },
      "source": [
        "for i, reg in enumerate(vor.regions):\n",
        "\n",
        "    print('Region:', i)\n",
        "    print('Indices of vertices of Voronoi region:', reg)\n",
        "    print('Associated point:', rest_data[reg], '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdGIUnW5F2No"
      },
      "source": [
        "# **Area and Total Number of Points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajqvhvz9Zy5E"
      },
      "source": [
        "def PolyArea2D(pts):\n",
        "    lines = np.hstack([pts,np.roll(pts,-1,axis=0)])\n",
        "    area = 0.5*abs(sum(x1*y2-x2*y1 for x1,y1,x2,y2 in lines))\n",
        "    return area\n",
        "\n",
        "cell_area = []\n",
        "number_of_points = []\n",
        "corresponding_centroid = []\n",
        "\n",
        "for i in range(len(centroid)):\n",
        "  print(\"points\",[i], \"=\", centroid[i],'and no of  points inside it','-->',count[vor.point_region[i]])\n",
        "  corresponding_centroid.append(centroid[i])\n",
        "  number_of_points.append(count[vor.point_region[i]])\n",
        "  print('Area-->',PolyArea2D(vor.vertices[vor.regions[vor.point_region[i]]]))\n",
        "  cell_area.append(PolyArea2D(vor.vertices[vor.regions[vor.point_region[i]]]))\n",
        " \n",
        "\n",
        "print(len(cell_area),len(number_of_points))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w2lOZImrrci"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "distance_matrix= cosine_similarity(centroid,centroid)\n",
        "print(distance_matrix)\n",
        "\n",
        "type(centroid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffZu1_4-ZZq0"
      },
      "source": [
        "\n",
        "points_centroid = dict(zip(number_of_points,corresponding_centroid))\n",
        "print(points_centroid)\n",
        "# type(points_centroid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhxCBoDfal0P"
      },
      "source": [
        "import operator\n",
        "max(points_centroid.items(), key=operator.itemgetter(0))[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkLMQmARbXUP"
      },
      "source": [
        "max = []\n",
        "for i in (sorted((number_of_points),reverse = True)):\n",
        "  max.append(points_centroid.get(i))\n",
        "  print(points_centroid.get(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BRPMaiCGM_t"
      },
      "source": [
        "# **(No of points, Area)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrxYjXX0Kbxe"
      },
      "source": [
        "l = zip(number_of_points,cell_area)\n",
        "points_area = (list(l))\n",
        "print((points_area))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y55lgdIGW5w"
      },
      "source": [
        "# **Density Array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlwMRnXh0kIg"
      },
      "source": [
        "from operator import truediv\n",
        "density_value = list(map(truediv,number_of_points,cell_area))\n",
        "sorted_density_list = (sorted((density_value),reverse = True))\n",
        "print(sorted_density_list)\n",
        "print((density_value))\n",
        "\n",
        "# final_centroid1= np.argmax(density_value)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBMFsLiQGel_"
      },
      "source": [
        "# **Top density wise Centroid point index**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJTS85kYli_A"
      },
      "source": [
        "index = sorted(range(len(density_value)),reverse = True, key=density_value.__getitem__)\n",
        "print(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxqzmTDxG3wL"
      },
      "source": [
        "# **Top Centroid List**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh3z19MJzVcr"
      },
      "source": [
        "rank_wise_centroid = []\n",
        "for i in range(0,len(index)):\n",
        "  rank_wise_centroid.append(centroid[index[i]])\n",
        "# print(rank_wise_centroid)\n",
        "\n",
        "\n",
        "for i,j in enumerate(rank_wise_centroid):\n",
        "  print(\"rank\",i,\"--->\",j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwRB5tIDRxtE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ0BdUuaG9p4"
      },
      "source": [
        "# **1st CENTROID**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0JdY7d-M656"
      },
      "source": [
        "final_centroid1 = rank_wise_centroid[0]\n",
        "print(\"THIS IS CENTROID 1:-\",final_centroid1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLTTO6WzHEKN"
      },
      "source": [
        "# **Next CENTROIDs Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKbdIFHcz7Tf"
      },
      "source": [
        "bool_arr0 = []\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "distance_matrix= cosine_similarity(rank_wise_centroid,rank_wise_centroid)\n",
        "# print(distance_matrix[0])\n",
        "\n",
        "for i in range(len(distance_matrix[0])):\n",
        "  if distance_matrix[0][i] <= 0.5:\n",
        "    bool_arr0.append(True)\n",
        "  else:\n",
        "    bool_arr0.append(False)\n",
        "print(bool_arr0)\n",
        "\n",
        "\n",
        "distance_matrix_checker_index = []\n",
        "possible_centroid2 = []\n",
        "for i in range(len(bool_arr0)):\n",
        "  if bool_arr0[i] == True:\n",
        "    possible_centroid2.append(rank_wise_centroid[i])\n",
        "    distance_matrix_checker_index.append(i)\n",
        "if len((possible_centroid2)) == 0:\n",
        "  print(\"NEXT ITERATION\")\n",
        "else:\n",
        "  final_centroid2 = possible_centroid2[0]\n",
        "  print(\" IS THIS CENTROID 2?:-\",final_centroid2, \"next will check in destance_matrix\",[distance_matrix_checker_index[0]],\":-\")\n",
        "  # print(distance_matrix_checker_index)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkmh3IkwSV_c"
      },
      "source": [
        "# *COLLECTED CENTROIDS FOR THIS MODEL*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **clus_1 = [3.49992004,0.4606741]**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **clus_2 = [-2.62614497,0.16338496]**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **clus_3 = [ 0.94473373, -0.54314555]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK41JSeuJF9-"
      },
      "source": [
        "bool_arr_five = []\n",
        "\n",
        "# print(distance_matrix[0])\n",
        "\n",
        "for i in range(len(distance_matrix[5])):\n",
        "  if distance_matrix[5][i] <= 0.5:\n",
        "    bool_arr_five.append(True)\n",
        "  else:\n",
        "    bool_arr_five.append(False)\n",
        "print(bool_arr_five)\n",
        "\n",
        "\n",
        "# # distance_matrix_checker_index = []\n",
        "# possible_centroid2 = []\n",
        "# for i in range(len(bool_arr0)):\n",
        "#   if bool_arr0[i] == True:\n",
        "#     possible_centroid2.append(rank_wise_centroid[i])\n",
        "#     distance_matrix_checker_index.append(i)\n",
        "# if len((possible_centroid2)) == 0:\n",
        "#   print(\"NEXT ITERATION\")\n",
        "# else:\n",
        "#   final_centroid2 = possible_centroid2[0]\n",
        "#   print(\" IS THIS CENTROID 2?:-\",final_centroid2)\n",
        "#   # print(distance_matrix_checker_index)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJZ2nmRIVLZu"
      },
      "source": [
        "# print(distance_matrix)\n",
        "# print(distance_matrix[0])\n",
        "print(distance_matrix[5])\n",
        "print(distance_matrix[1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-ql0ijQQ4Q"
      },
      "source": [
        "vector1 = [1, 2]\n",
        "vector2 = [3, 2]\n",
        "\n",
        "cosine_similarity = 1 - spatial.distance.cosine(vector1, vector2)\n",
        "print(cosine_similarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTNowqPl_RNj"
      },
      "source": [
        "import scipy\n",
        "from scipy import sparse\n",
        "sparse_matrix= scipy.sparse.csr_matrix(centroid)\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "distance_matrix= pairwise_distances(sparse_matrix, metric=\"cosine\")\n",
        "\n",
        "print(distance_matrix)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FXm6VnD60F9"
      },
      "source": [
        "# **Top 3 Crowded Cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNLYLK_a0zUK"
      },
      "source": [
        "\n",
        "from heapq import nlargest,nsmallest\n",
        "# Initialize N\n",
        "N = 5\n",
        "res = nlargest(N, count, key = count.get)\n",
        "\n",
        "print(\"The top 3 value cells are \" + str(res))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLm-5QTz68Eg"
      },
      "source": [
        "# **Centroid Point of those 3 cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFEHZxcN08kA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9QDBM0B7ICn"
      },
      "source": [
        "# **Distance Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX42cAnB1G1E"
      },
      "source": [
        "from scipy.spatial import distance\n",
        "distance.cdist(cell_centr_tracker, cell_centr_tracker, 'euclidean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCbfkxqjsybY"
      },
      "source": [
        "!pip install scipy\n",
        "import scipy\n",
        "from scipy import sparse\n",
        "sparse_matrix= scipy.sparse.csr_matrix(cell_centr_tracker)\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "distance_matrix= pairwise_distances(sparse_matrix, metric=\"cosine\")\n",
        "print(distance_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}